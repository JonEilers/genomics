Genome Annotation
=====

.. _Genome Annotation:

While creating a high quality, contiguous genome assembly is critical to any genomics or genetics project, a genome assembly is practically useless without identifying and annotating the various components of a genome such as genes, transposable elements, promoters, transcription factor binding sites, etc. This is currently where the real challenge lays in most genome sequencing projects and the consequences of doing this poorly can impact future analyses. Including propagation of those `errors to other genomes <https://genomebiology.biomedcentral.com/articles/10.1186/s13059-019-1715-2>`_ as is `commonly seen on NCBI <https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-020-03855-1>`_ when performing blast searches for homologs and orthologs where up to an estimated 50% of genes contain errors. 

The most common example of errors in a genome assembly is simply gene content and is often seen in the change in gene content as observed in subsequent versions of a genome assembly. One such example is that of the saugaro cactus. In 2017, a `draft assembly (SGP5 v1.3) <https://www.pnas.org/doi/full/10.1073/pnas.1706367114>`_ was published with 28,292 genes. In 2023, a `pre-print <https://www.biorxiv.org/content/10.1101/2023.04.11.536419v2.full>`_  was uploaded to biorxiv on an improved saguaro cactus genome assembly (SGP5p v2) that had 34,209 protein-coding gene models. Any genome wide analysis of incomplete assemblies would inherently be missing information. Even assemblies that are almost complete can have missing content such as seen when comparing the human reference genomes HG38 and complete `telomere to telomere (T2T) assembly <https://www.science.org/doi/full/10.1126/science.abj6987>`_ in which the number of genes increased from 60,090 to 63,494 and protein coding genes increased from 19,890 to 19,969. 

Gene content is not the only challenge though, acquiring correct gene model structures has proven difficult. One such example is the `Bartlett double haploid pear genome <https://academic.oup.com/gigascience/article-abstract/8/12/giz138/5670615>`_  published in 2019. `Close analysis of several gene families <https://www.frontiersin.org/articles/10.3389/fpls.2022.975942/full>`_ using a combination of multiple sequence alignment of orthologs and RNA-seq alignment revealed a significant number of gene models were incorrect due to assembly errors producing resulting in reading frames shifts and stop codons which likely confounded the gene prediction tools. This is all to say, this is an important step and not performing due deligence in checking gene models and annotation for mistakes can have downstream effects on others. If the genome assembly is fragmented or "low-quality", I personally recommend only uploading the assembly to NCBI. If gene models or annotations are also uploaded they will likely contain errors that will be propagated to other assemblies and analyses. 

.. figure:: /annotation/annotation_page_assets/annotation_short_version.png
   :align: left
   :figwidth: 50%

That said, let's take a look at what it takes to predict gene models and functional annotations. The primary steps are: repetitive elements identification and masking, gene expression data mapping, protein database alignment, de novo gene prediction, and functional annotation of gene models. While this is the primary pipeline for gene prediction, the genome contains numerous other sequences of interest such as `cis-regulatory elements <https://en.wikipedia.org/wiki/Cis-regulatory_element>`_, `non-coding genes <https://en.wikipedia.org/wiki/Non-coding_DNA>`_, and organelle genomes such as `mitochondria <https://en.wikipedia.org/wiki/Mitochondrial_DNA>`_ and `chloroplasts <https://en.wikipedia.org/wiki/Chloroplast_DNA>`_, and there are a number of tools and analyses that can be done to find those. These additional steps will be covered later though. 

Repetitive Element Identification and Masking
----------

The first step is identifying and masking `repetitive elements <https://en.wikipedia.org/wiki/Repeated_sequence_(DNA)>`_ (RE) and `transposons <https://en.wikipedia.org/wiki/Transposable_element>`_ (TE) in the genome assembly. This is mostly to reduce the computational load during gene prediction as genomes can be up to two-thirds or more TEs and REs. By masking them, the gene prediction tools only have to search a much smaller sequence space for genes. However, as noted later, TEs have genes and genes are sometimes located in RE such as in the `centromeres <https://www.science.org/doi/full/10.1126/science.abl4178>`_ and `subtelomeres <https://www.sciencedirect.com/science/article/pii/S0022283620300905>`_ of chromosomes. So this step should not be considered lightly and the result should be analyzed with care and an eye for mis-masked regions. 

Identifying repetitive elements in genome assemblies is an underappreciated task which is often performed in order to get to the "interesting" parts of the genome such as genes. However, it is looking more and more like genome assembly and annotation projects should also invest time into identifying and annotating the repetitive elements of the genome too. This paper - "`A Roadmap for Understanding the Evolutionary Significance of Structural Genomic Variation <https://www.sciencedirect.com/science/article/abs/pii/S0169534720300768>`_ outlines the importance of studying structural genome variation which includes incorporating repetitive elements into a broader understanding of genome regulation and evolution. 

* :doc:`An Introduction to Repetitive Elements and Transposable Elements </annotation/repetitive_elements>`
* :doc:`Using TeTools to Identify and Mask Repetitive Elements and Transposons </annotation/tetools>`
* :doc:`Manual Annotation and Curation of Transposable Elements </annotation/manual_te_annotation>`

Expression Data Mapping and Protein Database Alignment
----------

The next two steps are gene expression data (`rna-seq <https://en.wikipedia.org/wiki/RNA-Seq>`_) mapping and protein database alignment(e.g. `Uniprot <https://en.wikipedia.org/wiki/UniProt>`_ and `Refseq <https://en.wikipedia.org/wiki/RefSeq>`_). Mapping rna-seq data represents gene expression and is key data for finding where genes are located in a genome and what the structure of the gene is (i.e. `exons <https://en.wikipedia.org/wiki/Exon>`_ and `introns <https://en.wikipedia.org/wiki/Intron>`_). Additionally, publicly available protein databases contain millions of protein sequences which can be used to inform where start, stop, and splice sites are located. This can be particularly useful as gene expression data does not always contain information on every gene. This is due to gene expression being tissue specific and if there is no gene expression atlas of all tissue types and developmental stages, then some genes may not have expression data to corroborate their existence. Additionaly, protein databases can contain manually curated gene models where someone has checked the evidence for the gene stucture and corrected any errors.

* :doc:`Mapping Gene Expression Data to the Genome Assembly </annotation/rna-seq_mapping>`
* :doc:`Aligning Protein Databases to the Genome Assembly </annotation/protein_database_alignment>`

Gene Model Prediction
----------

Gene prediction, the process of identifying regions of a genome that encode genes, is a fundamental aspect of genomic analysis. Modern gene prediction tools like Braker and Maker utilize a masked genome, where repetitive elements are hidden, and incorporate mapped extrinsic data such as RNA-seq and protein alignments. These tools also rely on intrinsic knowledge of gene structure, including start and stop codons, splice sites, and untranslated regions, to construct putative gene models. However, achieving accurate gene prediction remains a complex challenge. One primary difficulty lies in assembly errors, which can lead to reading frame shifts and inaccurately identified stop codons and splice sites. Additionally, the gene content and structure can vary significantly between species due to factors like transposons, recombination, and genome duplication, which rearrange genomes. Furthermore, a lack of comprehensive gene expression data can hinder the ability to identify all genes accurately.

Despite these challenges, automatic methods have become the mainstream approach for initial gene prediction due to the vast size of most genomes and the enormous number of genes they contain. These computational tools provide a foundation for gene annotation but often fall short of the accuracy achieved by manual curation. Manual curation, considered the gold standard, involves a thorough examination of gene expression and protein alignment data to assess and refine gene models. This process is time-consuming and labor-intensive, requiring expert knowledge and a detailed analysis of genomic data. As a result, few projects undertake comprehensive manual curation. However, in recent years, there has been a significant push to manually curate the complete gene sets of specific organisms and particular gene subsets, such as olfactory genes in mice and humans.

* :doc:`Gene Prediction using Braker <annotation/braker_gene_prediction>`
* :doc:`Gene Prediction using Maker and Augustus <annotation/maker_gene_prediction>`
* :doc:`Combining Evidence using EvidenceModler or Tserba <annotation/combining_evidence>`
* :doc:`Visualizing and Editing Gene Models <annotation/manual_curation>`

Functional Annotation and Analysis
----------

Functional annotation in genome analysis is a crucial process that involves assigning biological functions to gene products, such as proteins or RNAs. This step is essential for transforming raw sequence data into meaningful biological information. The significance of functional annotation lies in its ability to facilitate comparative studies across different species, enable functional enrichment analyses, and aid in understanding the evolutionary and functional dynamics of genomes. By providing insights into the roles of genes in various biological processes and conditions, functional annotations enrich our understanding of gene functionality within the broader context of cellular and organismal biology.

The process of functional annotation employs several methods and tools. Gene Ontology (GO) prediction is a primary approach, where GO terms describing biological processes, cellular components, and molecular functions are assigned to genes based on sequence similarity to known genes. Tools like Blast2GO or InterProScan are commonly used for this purpose. Another approach is the identification of protein domains using tools such as Pfam and SMART. These tools detect specific structural motifs within proteins that are often associated with particular functions. Homology-based methods, notably BLAST searches against comprehensive databases like NCBI’s non-redundant database or UniProt, are also widely used. These methods find orthologs or closely related sequences, allowing researchers to infer the functions of newly annotated genes based on their known relatives.

However, functional annotation is not without its challenges. A significant issue is the propagation of errors; if an initial annotation in a database is incorrect, this error can be perpetuated and magnified across subsequent studies and databases. This problem is particularly acute with homology-based methods that rely heavily on existing annotations. To counter this, manual verification of gene annotations is strongly recommended, especially for critical research areas. This involves a detailed comparison of the gene with known orthologs, examination of literature, and consideration of experimental data, ensuring a more accurate and reliable annotation.

In practice, a hierarchical approach is often employed in functional annotation. Typically, researchers first attempt to assign GO terms. If this is not possible, they then look for known protein domains. When both these approaches yield no results, homology-based methods are used. If there is still no clear annotation, genes are often labeled as “uncharacterized” or “hypothetical proteins.” This cautious, step-wise approach helps in mitigating the risk of propagating errors.

The field of functional annotation, while rich in tools and methods, lacks a unified standard, leading to a variety of approaches with varying levels of accuracy and reliability. Researchers must judiciously choose tools and methods, balancing the need for comprehensive annotation with the risk of error. This careful and considered approach to functional annotation is vital for the accurate interpretation of genomic data, ultimately advancing our understanding of biological systems and their implications in health and disease. The continuous development and refinement of annotation tools, coupled with rigorous validation practices, are essential to ensure the reliability and utility of genomic annotations in scientific research.

* :doc:`Functional Annotation using Gene Ontology <annotation/gene_ontology>`
* :doc:`Protein Domain Annotation using InterProScan and EggNOG-mapper <annotation/protein_domain_annotation>`
* :doc:`Ortholog search using Blast and NCBI <annotation/annotation_via_ortholog>`
* :doc:`Evalauting functional annotations <annotation/functional_evaluation>`


Non-Coding RNA
--------------

The human genome, a vast and intricate blueprint of life, is predicted to contain over 60,000 genes, yet less than 20,000 of these are believed to be protein-coding. This disparity raises an intriguing question: what functions do the remaining genes serve? The answer lies in the realm of non-coding RNAs (ncRNAs), which play critical roles in the molecular and cellular machinery of organisms. Non-coding RNAs come in various forms – from long non-coding RNAs (lncRNAs) involved in transcriptional regulation to microRNAs (miRNAs) and small interfering RNAs (siRNAs) that modulate gene expression post-transcriptionally. 

In addition to their role in gene regulation, ncRNAs are pivotal in `epigenetic modulation <https://www.nature.com/articles/s41580-022-00566-8>`_, altering gene expression patterns over time through mechanisms like DNA methylation and histone modification. This function is crucial during development and differentiation in multicellular organisms. Structurally, ncRNAs such as ribosomal RNA (rRNA) and transfer RNA (tRNA) are fundamental components of the protein synthesis machinery. They are also involved in essential cellular processes including cell cycle regulation, apoptosis, and stress responses. The versatility and indispensability of ncRNAs in biological systems are thus evident.

Moreover, the significance of ncRNAs extends to disease contexts, with their dysregulation being linked to various diseases including `cancers, neurological disorders, and heart diseases <https://link.springer.com/article/10.1007/s10142-022-00947-4>`_. This association offers insights into disease mechanisms and potential therapeutic targets. Additionally, ncRNAs facilitate intercellular communication, often found in exosomes and influencing neighboring or distant cells. Their conservation across species underscores their evolutionary importance. Therefore, identifying and properly annotating ncRNAs in the genome assembly is not just a matter of cataloging; it's a crucial step in unraveling the complex orchestration of life at the molecular level, revealing intricate mechanisms fundamental to both health and disease. The ongoing discovery and study of ncRNAs continue to illuminate the vast, uncharted territories of non-protein-coding genes, offering profound insights into the complexities of `genetic regulation and function <https://www.sciencedirect.com/science/article/abs/pii/S1874939919302160>`_.

Because of the difficulty in differentiating ncRNA from protein-coding RNA, a combination of bioinformatic tools and ncRNA databases are utilized to identify and annotate ncRNA. Databases include: `NONCODE <http://www.noncode.org/>`_, `RNAcentral <https://rnacentral.org/>`_, `FANTOM <https://fantom.gsc.riken.jp/>`_, `RFAM <https://rfam.org/>`_, etc. Tools for identifying and annotating ncRNA are also numerous such as `Infernal <http://eddylab.org/infernal/>`_ and ncRNA type-specific tools such as for `tRNA <http://gtrnadb.ucsc.edu/>`_, `lncRNA <https://academic.oup.com/nar/article/45/8/e57/2798184?login=false>`_, `miRs <https://tools4mirs.org/>`_, and the list goes on (`piRNA, tsRNA, rRNA, snoRNA, sRNA, etc <https://pubmed.ncbi.nlm.nih.gov/29730207/>`_)

* :doc:`An attempt at finding all the ncRNAs in an assembly <>`


Note on additional datatypes and what more can be studied
-----------------------

Everything up to this point has focused on getting a genome assembly and annotating the genes within it. Realistically though, that is just the beginning of what can be identified and annotated within a genome. Genomes are extraordinarly complex, and we are only beginning to understand how chromatin conformation, post-translation modifications of proteins and RNA, and methylation control cell phenotype which culminates in the phenotypes we see and the development of whole multicellular organism from a single, amorphus, cell. I want to make a brief note on additional data-types and what further annotations can be achieved using them.

High-resolution Hi-C
~~~~~~~~~~~
High-resolution Hi-C is an advanced genomic technique that offers a detailed view of the three-dimensional organization of chromosomes within the cell nucleus. It enhances the basic Chromatin Conformation Capture (3C) method by providing a comprehensive and high-resolution map of chromosomal interactions. The process begins with chemically fixing chromatin in cells to preserve physical interactions, followed by digestion with a restriction enzyme and subsequent ligation to form chimeric DNA molecules. These molecules represent physical contacts between different genomic regions. Sequencing these fragments and mapping the reads back to the reference genome reveals the intricate web of interactions across the entire genome.

This technique is instrumental in identifying chromatin interactions, including those between distant genomic regions, which are key to understanding gene regulation mechanisms. High-resolution Hi-C maps how different chromosomes are positioned and interact in the nucleus, illuminating chromosome territories and the structure of Topologically Associating Domains (TADs). These TADs are crucial in gene regulation and genomic stability. Additionally, Hi-C detects looping interactions between promoters and enhancers, shedding light on the dynamic processes governing gene expression.

The high resolution of this method offers significant advantages over earlier 3C-based techniques. It provides a more detailed view of the chromatin architecture, essential for understanding the complex interplay between chromatin organization and gene regulation. High-resolution Hi-C is invaluable in various research areas, including developmental biology, where it helps elucidate the role of chromatin structure in cell differentiation, and in cancer research, where it can reveal chromatin organization changes associated with tumorigenesis. In summary, high-resolution Hi-C is a key tool in genomic research, enhancing our understanding of the spatial organization of the genome and its impact on cellular function in health and disease.

ATAC-Seq
~~~~~~~~
ATAC-Seq (Assay for Transposase-Accessible Chromatin using Sequencing) is a modern technique used to investigate the accessibility of chromatin, which is integral to understanding gene regulation. The basic principle of ATAC-Seq involves utilizing a transposase enzyme that inserts sequencing adapters into regions of open chromatin. These open regions are typically nucleosome-free or have fewer DNA-binding proteins, indicating potential activity in gene regulation. The DNA fragments with the inserted adapters are then sequenced, and the resulting sequence data reflects the regions of the genome that were accessible to the transposase, thus highlighting the active regulatory regions.

ATAC-Seq is particularly effective in identifying and studying cis-regulatory elements like promoters and enhancers. By mapping areas of open chromatin, ATAC-Seq pinpoints potential regulatory elements across the genome. When this data is correlated with gene expression profiles obtained from RNA-Seq, researchers can establish links between accessible chromatin regions and actively transcribed genes. This correlation is crucial in identifying the functional promoters and enhancers that regulate specific genes. Additionally, the integration of ATAC-Seq data with other genomic datasets, such as ChIP-Seq for transcription factors or histone modifications, provides a more nuanced understanding of how these regulatory elements function and interact with other components of the genome.

The strengths of ATAC-Seq lie in its high resolution and sensitivity, allowing for precise mapping of regulatory elements, and its efficiency, requiring less starting material compared to other methods. This makes it particularly suitable for studies with limited samples, such as single-cell analyses. Its rapid and straightforward protocol further enhances its applicability across various biological samples and conditions. As a result, ATAC-Seq has become a valuable tool in fields like developmental biology, disease research, and epigenetics, offering insights into how changes in chromatin accessibility impact gene regulation and contribute to different cellular states and functions. Through its detailed mapping of the regulatory landscape, ATAC-Seq enhances our understanding of the complex mechanisms of gene regulation.

WGBS
~~~~
Whole Genome Bisulfite Sequencing (WGBS) and its variants are powerful tools for studying DNA methylation, a key epigenetic modification involved in gene regulation. WGBS involves the treatment of DNA with sodium bisulfite, which converts unmethylated cytosines to uracil, while leaving methylated cytosines unchanged. This chemical alteration allows for the distinction between methylated and unmethylated cytosines during subsequent sequencing. The sequence data obtained provides a comprehensive map of methylation patterns across the entire genome, revealing how these patterns vary across different genomic regions, cell types, and developmental stages.

Variants of WGBS have been developed to address specific research needs and constraints. Reduced Representation Bisulfite Sequencing (RRBS) targets CpG-rich areas of the genome, such as promoters and enhancers, providing a focused view of methylation in these key regulatory regions. This method uses restriction enzymes to cut DNA and then applies bisulfite sequencing, making it a more cost-effective approach than WGBS for targeted studies. Another variant, Oxidative Bisulfite Sequencing (oxBS-Seq), distinguishes between 5-methylcytosine and 5-hydroxymethylcytosine, two forms of DNA methylation that have different biological roles. This distinction is crucial for understanding the nuanced functions of these epigenetic marks, especially in neural development and diseases.

WGBS and its variants are invaluable for understanding the role of DNA methylation in gene regulation, development, and disease. By providing a comprehensive view of methylation patterns, WGBS offers insights into the epigenetic mechanisms that underlie gene expression changes in various biological contexts. For instance, in cancer research, WGBS can reveal methylation changes that contribute to oncogenesis and tumor progression. In developmental biology, it helps in elucidating the dynamic changes in methylation during cell differentiation and organ development. The ability to map DNA methylation genome-wide offers an unprecedented window into the complex regulatory networks governing cellular function and identity.
